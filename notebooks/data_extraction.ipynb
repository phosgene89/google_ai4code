{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "699d023b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "222cf280",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_json = Path('../data/train/')\n",
    "test_json = Path('../data/test/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4d440d93",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_notebook(json_path):\n",
    "    \"\"\"This function is from\n",
    "    https://www.kaggle.com/code/corneliuskristianto/google-ai4code-reconstruct-the-order\n",
    "    \n",
    "    Read a json file from the Google AI4Code Kaggle competition into a pandas dataframe.\n",
    "    \n",
    "    Arguments\n",
    "    ---------\n",
    "    path: pathlib.Path\n",
    "        Path to json file.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    \"\"\"\n",
    "    nb_dataframe = pd.read_json(json_path,\n",
    "                                dtype={'cell_type': 'category', 'source': 'str'}\n",
    "                               ).assign(id=path.stem).rename_axis('cell_id')\n",
    "    \n",
    "    return nb_dataframe\n",
    "\n",
    "def read_json_folder(data_path):\n",
    "    \"\"\"This function is from\n",
    "    https://www.kaggle.com/code/corneliuskristianto/google-ai4code-reconstruct-the-order\n",
    "    \"\"\"\n",
    "    paths_train = list((data_path).glob('*.json'))\n",
    "    notebooks_train = [\n",
    "        read_notebook(path) for path in tqdm(paths_train, desc='NBs loaded')\n",
    "    ]\n",
    "\n",
    "    df = (pd.concat(notebooks_train)\n",
    "            .set_index('id', append=True)\n",
    "        .swaplevel()\n",
    "        .sort_index(level='id', sort_remaining=False))\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "682758c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = load_dataset(train_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ac4b6261",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00, 307.51it/s]\u001b[A\n"
     ]
    }
   ],
   "source": [
    "test_df = load_dataset(test_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c3818534",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(\"../generated_data/train_df.parquet\") is False:\n",
    "    train_df = load_dataset(train_json)\n",
    "    \n",
    "else:\n",
    "    train_df = pd.read_parquet(\"../generated_data/train_df.parquet\")\n",
    "\n",
    "if os.path.exists(\"../generated_data/test_df.parquet\") is False:\n",
    "    test_df = load_dataset(test_json)\n",
    "    \n",
    "else:\n",
    "    test_df = pd.read_parquet(\"../generated_data/test_df.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "284bcb59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get an example notebook\n",
    "nb_id = df.index.unique('id')[6]\n",
    "print('Notebook:', nb_id)\n",
    "\n",
    "print(\"The disordered notebook:\")\n",
    "nb = df.loc[nb_id, :]\n",
    "display(nb)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa669e22",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_orders = pd.read_csv(\n",
    "    DATA_DIR / 'train_orders.csv',\n",
    "    index_col='id',\n",
    "    squeeze=True,\n",
    ").str.split()  # Split the string representation of cell_ids into a list\n",
    "\n",
    "df_orders.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22586610",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the correct order\n",
    "cell_order = df_orders.loc[nb_id]\n",
    "\n",
    "print(\"The ordered notebook:\")\n",
    "nb.loc[cell_order, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "388838d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ranks(base, derived):\n",
    "    return [base.index(d) for d in derived]\n",
    "\n",
    "cell_ranks = get_ranks(cell_order, list(nb.index))\n",
    "nb.insert(0, 'rank', cell_ranks)\n",
    "\n",
    "nb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4deb85da",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_orders_ = df_orders.to_frame().join(\n",
    "    df.reset_index('cell_id').groupby('id')['cell_id'].apply(list),\n",
    "    how='right',\n",
    ")\n",
    "\n",
    "ranks = {}\n",
    "for id_, cell_order, cell_id in df_orders_.itertuples():\n",
    "    ranks[id_] = {'cell_id': cell_id, 'rank': get_ranks(cell_order, cell_id)}\n",
    "\n",
    "df_ranks = (\n",
    "    pd.DataFrame\n",
    "    .from_dict(ranks, orient='index')\n",
    "    .rename_axis('id')\n",
    "    .apply(pd.Series.explode)\n",
    "    .set_index('cell_id', append=True)\n",
    ")\n",
    "\n",
    "df_ranks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10dc0ac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ancestors = pd.read_csv(DATA_DIR / 'train_ancestors.csv', index_col='id')\n",
    "df_ancestors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ab7aa40",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "\n",
    "NVALID = 0.1  # size of validation set\n",
    "\n",
    "splitter = GroupShuffleSplit(n_splits=1, test_size=NVALID, random_state=0)\n",
    "\n",
    "# Split, keeping notebooks with a common origin (ancestor_id) together\n",
    "ids = df.index.unique('id')\n",
    "ancestors = df_ancestors.loc[ids, 'ancestor_id']\n",
    "ids_train, ids_valid = next(splitter.split(ids, groups=ancestors))\n",
    "ids_train, ids_valid = ids[ids_train], ids[ids_valid]\n",
    "\n",
    "df_train = df.loc[ids_train, :]\n",
    "df_valid = df.loc[ids_valid, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "629f9804",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ba00cb4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e38a46c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7ee8ddd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09d906c4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
